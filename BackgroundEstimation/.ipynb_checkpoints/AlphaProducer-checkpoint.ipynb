{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017bb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import uproot4 as uproot\n",
    "import uproot \n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3ff840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def set_sns_color(*args):\n",
    "    sns.palplot(sns.color_palette(*args))\n",
    "    sns.set_palette(*args)\n",
    "    \n",
    "color_order_bkg = sns.color_palette('Accent', 3)\n",
    "color_order_bkg.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0207d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_helvet = True  ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890e74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"/cms/user/guojl/ME_test/CMSSW_10_6_26/src/HZZAnalysis/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32ae0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7b3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#var to read\n",
    "var_read_lists = ['pt2l','mass2l','EventWeight','foundZ1LCandidate','foundTTCRCandidate','foundZ2JCandidate','foundZ2MergedCandidata','foundTTCRCandidate','passedfullmerged','passedfullresolved','particleNetZvsQCD','passedNassociated','isEE','isMuMu',\n",
    "                        'massmerged','ptmerged',\n",
    "                        'pt2jet','mass2jet',\n",
    "                        'mass2l2jet', 'mass2lj',\n",
    "                        'KD_jjVBF',\n",
    "                         'isbjet','iscjet','islightjet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8962aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_dir = '/cms/user/guojl/Sample/2L2Q/UL_Legacy/2016/'\n",
    "samples_inf = {#name path cross Section\n",
    "                    #'DY_pt50To100':['MC/DYJetsToLL_Pt-50To100_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8', 363.8142],\n",
    "                    'DY_pt50To100':['MC/DYJetsToLL_Pt-50To100_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8', 398.8],\n",
    "                    #'DY_pt100To250':['MC/DYJetsToLL_Pt-100To250_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8',84.014804],\n",
    "                    'DY_pt100To250':['MC/DYJetsToLL_Pt-100To250_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8',93.61],\n",
    "                    'DY_pt250To400':['MC/DYJetsToLL_Pt-250To400_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8',3.67],#3.047],\n",
    "                    'DY_pt400To650':['MC/DYJetsToLL_Pt-400To650_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8',0.5],#0.392],\n",
    "                    'DY_pt650ToInf':['MC/DYJetsToLL_Pt-650ToInf_MatchEWPDG20_TuneCP5_13TeV-amcatnloFXFX-pythia8',0.04704],#0.03636],\n",
    "                    'TTJets':['MC/TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8',831.76],\n",
    "                    'TTTo2L2Nu':['MC/TTTo2L2Nu_TuneCP5_13TeV-powheg-pythia8',1],\n",
    "                    'WW_TuneCP5':['MC/WW_TuneCP5_13TeV-pythia8',1],\n",
    "                    'WWTo2L2Nu':['MC/WWTo2L2Nu_TuneCP5_13TeV-powheg-pythia8',11.09],\n",
    "                    'WZTo2Q2L':['MC/WZTo2Q2L_mllmin4p0_TuneCP5_13TeV-amcatnloFXFX-pythia8',6.419],\n",
    "                    'ZZTo2Q2L':['MC/ZZTo2Q2L_mllmin4p0_TuneCP5_13TeV-amcatnloFXFX-pythia8',3.696],\n",
    "                    'ggH1000':['MC/Signal/skimed/GluGluHToZZTo2L2Q_M1000_TuneCP5_13TeV_powheg2_JHUGenV7011_pythia8__asymptotic_v17-v2_0.root',5.07],\n",
    "                    'VBF1500':['MC/Signal/skimed/VBF_HToZZTo2L2Q_M1500_TuneCP5_13TeV_powheg2_JHUGenV7011_pythia8__asymptotic_v13-v1_0.root',0.77],\n",
    "                    'test':'MC/test',\n",
    "                    'Data':['Data/skimed/Data2016UL_noDuplicates.root',1],\n",
    "                    }\n",
    "\n",
    "Samples_lists = ['DY_pt50To100','DY_pt100To250','DY_pt250To400','DY_pt400To650','DY_pt650ToInf',\n",
    "              'TTJets',\n",
    "              'WZTo2Q2L',\n",
    "              'ZZTo2Q2L',\n",
    "              'WWTo2L2Nu',\n",
    "              'Data']\n",
    "\n",
    "#signal_lists = [ 'ggH1000','VBF1500']\n",
    "signal_lists = [ 'ggH1000']\n",
    "\n",
    "lumi = {2016: 16.81, 2017: 41.53, 2018: 59.74}\n",
    "year=2016\n",
    "\n",
    "bininfo = {'mass2l':[24,60,120,\"M(ll)\"],\n",
    "              'pt2l':[70,100,800,\"Pt(ll)\"],\n",
    "              #'massmerged':[28,40,180,\"M(J)\"],\n",
    "              'massmerged':[40,0,200,\"M(J)\"],\n",
    "              'ptmerged':[60,200,800,\"Pt(J)\"],\n",
    "              'mass2l2jet':[28,40,180,\"M(2l2q)\"], \n",
    "              'mass2lj':[60,500,3500,\"M(2l2q)\"],\n",
    "              'pt2jet':[70,100,800,\"Pt(jj)\"],\n",
    "              'mass2jet':[28,40,180,\"M(jj)\"],\n",
    "              'particleNetZvsQCD':[20,0,1,\"particleNetZvsQCD\"],\n",
    "              'KD_jjVBF':[20,0,1,\"VBF(score)\"]}\n",
    "\n",
    "cats = ['isEE','isMuMu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825c3155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is DY_pt50To100\n",
      "This is DY_pt100To250\n",
      "This is DY_pt250To400\n",
      "This is DY_pt400To650\n",
      "This is DY_pt650ToInf\n",
      "This is TTJets\n",
      "This is WZTo2Q2L\n",
      "This is ZZTo2Q2L\n",
      "This is WWTo2L2Nu\n",
      "This is Data\n",
      "This is ggH1000\n"
     ]
    }
   ],
   "source": [
    "#extract branch for each sample\n",
    "bkg_array = {}\n",
    "data_array = None\n",
    "signal_array = {}\n",
    "sumWeight = {}\n",
    "\n",
    "for sample in Samples_lists:\n",
    "    print(f\"This is {sample}\")\n",
    "    if sample!='Data':\n",
    "        indir = ori_dir+samples_inf[sample][0]+'/skimed'\n",
    "        files = find_this_rootfiles(indir)\n",
    "        sumWeight[sample] = 0\n",
    "            \n",
    "        for file in files:\n",
    "            with uproot.open(f'{indir}/{file}') as f:\n",
    "                this_sumWeight_h = f['sumWeights'].to_boost()\n",
    "                this_sumWeight = this_sumWeight_h.sum()\n",
    "                #print(f'this sum weight = {this_sumWeight}')\n",
    "                sumWeight[sample] += this_sumWeight\n",
    "                    \n",
    "        bkg_array[sample] = uproot.lazy([f\"{indir}/*.root:passedEvents\"],filter_name=var_read_lists)\n",
    "        \n",
    "    else:\n",
    "        data_path = ori_dir+samples_inf['Data'][0]\n",
    "        data_array = uproot.lazy([f\"{data_path}:passedEvents\"],filter_name=var_read_lists)\n",
    "\n",
    "for sample in signal_lists:\n",
    "    print(f\"This is {sample}\")\n",
    "    signal_path = ori_dir+samples_inf[sample][0]\n",
    "    \n",
    "    sumWeight[sample] = 0\n",
    "    with uproot.open(signal_path) as f:\n",
    "        this_sumWeight_h = f['sumWeights'].to_boost()\n",
    "        this_sumWeight = this_sumWeight_h.sum()\n",
    "        sumWeight[sample] += this_sumWeight\n",
    "        \n",
    "        signal_array[sample] = f['passedEvents'].arrays(filter_name=var_read_lists,library=\"ak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb9c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cut(array,region,cat): \n",
    "    if region=='CR':\n",
    "        selection = f'((massmerged<70) | (massmerged>105)) & (particleNetZvsQCD>0.9) & (foundZ1LCandidate==True) & (foundZ2MergedCandidata==True) & ({cat}==True)'\n",
    "        #cut_array = array['foundZ1LCandidate'] & array['foundZ2MergedCandidata'] & ((array['massmerged']<70) | (array['massmerged']>105) & (array['particleNetZvsQCD']>0.9)) #merged\n",
    "    elif region=='SR':\n",
    "        selection = f'(massmerged>70) & (massmerged<105) & (particleNetZvsQCD>0.9) & (foundTTCRCandidate==True) & (foundZ2MergedCandidata==True) & ({cat}==True)'\n",
    "        #cut_array = array['foundTTCRCandidate'] & array['foundZ2MergedCandidata'] & ((array['massmerged']<70) | (array['massmerged']>105) & (array['particleNetZvsQCD']>0.9)) #merged\n",
    "    else:\n",
    "        print(\"[ERROR] only CR and SR are available\")\n",
    "        sys.exit()\n",
    "    \n",
    "    cut_array = ak.numexpr.evaluate(selection,array)\n",
    "        \n",
    "    #cut_array = array[cat] & array['foundZ2JCandidate'] & ((array['mass2jet']<70) | (array['mass2jet']>105)) &array['passedNassociated']#resovled\n",
    "    #cut_array = array[cat] #leptonic Z\n",
    "    return cut_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545c041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce697174",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_particleNet_signal = {}\n",
    "with open('/cms/user/guojl/ME_test/CMSSW_10_6_26/src/HZZAnalysis/cards/NetSF_signal_2016Legacy.yml') as f:\n",
    "    sf_particleNet_signal = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0c8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is DY_pt50To100 in CR in isEE\n",
      "This is DY_pt100To250 in CR in isEE\n",
      "This is DY_pt250To400 in CR in isEE\n",
      "This is DY_pt400To650 in CR in isEE\n",
      "This is DY_pt650ToInf in CR in isEE\n",
      "This is TTJets in CR in isEE\n",
      "This is WZTo2Q2L in CR in isEE\n",
      "This is ZZTo2Q2L in CR in isEE\n",
      "This is WWTo2L2Nu in CR in isEE\n",
      "This is Data in CR in isEE\n",
      "This is DY_pt50To100 in CR in isMuMu\n",
      "This is DY_pt100To250 in CR in isMuMu\n",
      "This is DY_pt250To400 in CR in isMuMu\n",
      "This is DY_pt400To650 in CR in isMuMu\n",
      "This is DY_pt650ToInf in CR in isMuMu\n",
      "This is TTJets in CR in isMuMu\n",
      "This is WZTo2Q2L in CR in isMuMu\n",
      "This is ZZTo2Q2L in CR in isMuMu\n",
      "This is WWTo2L2Nu in CR in isMuMu\n",
      "This is Data in CR in isMuMu\n",
      "This is DY_pt50To100 in SR in isEE\n",
      "This is DY_pt100To250 in SR in isEE\n",
      "This is DY_pt250To400 in SR in isEE\n",
      "This is DY_pt400To650 in SR in isEE\n",
      "This is DY_pt650ToInf in SR in isEE\n",
      "This is TTJets in SR in isEE\n",
      "This is WZTo2Q2L in SR in isEE\n",
      "This is ZZTo2Q2L in SR in isEE\n",
      "This is WWTo2L2Nu in SR in isEE\n",
      "This is Data in SR in isEE\n",
      "This is DY_pt50To100 in SR in isMuMu\n",
      "This is DY_pt100To250 in SR in isMuMu\n",
      "This is DY_pt250To400 in SR in isMuMu\n",
      "This is DY_pt400To650 in SR in isMuMu\n",
      "This is DY_pt650ToInf in SR in isMuMu\n",
      "This is TTJets in SR in isMuMu\n",
      "This is WZTo2Q2L in SR in isMuMu\n",
      "This is ZZTo2Q2L in SR in isMuMu\n",
      "This is WWTo2L2Nu in SR in isMuMu\n",
      "This is Data in SR in isMuMu\n"
     ]
    }
   ],
   "source": [
    "#apply cut and for each sample\n",
    "regions = ['CR','SR']\n",
    "bkg_array_cut = {}; data_array_cut = {}; signal_array_cut = {}\n",
    "for reg in regions:\n",
    "    bkg_array_cut[reg] = {}; data_array_cut[reg] = {}; signal_array_cut[reg] = {}\n",
    "    for cat in cats:\n",
    "        bkg_array_cut[reg][cat] = {}; data_array_cut[reg][cat] = None; signal_array_cut[reg][cat] = {}\n",
    "        for sample in Samples_lists:\n",
    "            print(f\"This is {sample} in {reg} in {cat}\")\n",
    "            if sample!='Data':\n",
    "                temp_array = bkg_array[sample]\n",
    "                cut_array = make_cut(temp_array,region = reg, cat = cat)\n",
    "                bkg_array_cut[reg][cat][sample] = temp_array[cut_array]\n",
    "            else:\n",
    "                temp_array = data_array\n",
    "            \n",
    "                cut_array = make_cut(temp_array,region = reg, cat = cat)\n",
    "                data_array_cut[reg][cat] = temp_array[cut_array]\n",
    "        #for sample in signal_lists:\n",
    "        #    temp_array = signal_array[sample]\n",
    "        #    cut_array = make_cut(temp_array,region = reg, cat = cat)\n",
    "        #    signal_array_cut[reg][cat][sample] = temp_array[cut_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4607077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is DY_pt50To100 in isEE\n",
      "This is DY_pt100To250 in isEE\n",
      "This is DY_pt250To400 in isEE\n",
      "This is DY_pt400To650 in isEE\n",
      "This is DY_pt650ToInf in isEE\n",
      "This is TTJets in isEE\n",
      "This is WZTo2Q2L in isEE\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GetParticleNetSignalSF() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m weights \u001b[38;5;241m=\u001b[39m (temp_array[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventWeight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mlumi[\u001b[38;5;241m2016\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m*\u001b[39msamples_inf[sample][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39msumWeight[sample]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZZTo2Q2L\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m sample \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWZTo2Q2L\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     sf_Net \u001b[38;5;241m=\u001b[39m \u001b[43mGetParticleNetSignalSF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_array\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZvsQCD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msf_particleNet_signal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     25\u001b[0m     sf_Net \u001b[38;5;241m=\u001b[39m GetParticleNetbkgSF(temp_array,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZvsQCD\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: GetParticleNetSignalSF() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#set draw var\n",
    "var = 'mass2lj'\n",
    "nbins, xmin, xmax = bininfo[var][0], bininfo[var][1], bininfo[var][2]\n",
    "edge = np.linspace(xmin, xmax, nbins+1)\n",
    "if var.find('pt')!=-1 or var.find('massmerged')!=-1 or var.find('mass2jet')!=-1:\n",
    "    islogY = True\n",
    "else:\n",
    "    islogY = True\n",
    "\n",
    "#fill histo \n",
    "bkg_hists = {}; Data_hist = {}; signal_hists = {}\n",
    "for reg in regions:\n",
    "    bkg_hists[reg] = {}; Data_hist[reg] = {}; signal_hists[reg] = {}\n",
    "    for cat in cats:\n",
    "        bkg_hists[reg][cat] = [None,None,None]; Data_hist[reg][cat] = None; signal_hists[reg][cat] = []\n",
    "        for sample in Samples_lists:\n",
    "            print(f\"This is {sample} in {cat}\")\n",
    "            if sample!='Data':\n",
    "                temp_array = bkg_array_cut[reg][cat][sample]\n",
    "                #retray weight and apply paritcleNet weight\n",
    "                weights = (temp_array['EventWeight']*lumi[2016]*1000*samples_inf[sample][1])/sumWeight[sample]\n",
    "                if sample == 'ZZTo2Q2L' or sample =='WZTo2Q2L':\n",
    "                    sf_Net = GetParticleNetSignalSF(temp_array,'ZvsQCD',sf_particleNet_signal)\n",
    "                elif sample.find('DY')!=-1:\n",
    "                    sf_Net = GetParticleNetbkgSF(temp_array,'ZvsQCD','DY')\n",
    "                elif sample.find('TTJets')!=-1 or sample.find('WWTo2L2Nu')!=-1:\n",
    "                    sf_Net = GetParticleNetbkgSF(temp_array,'ZvsQCD','TT')\n",
    "                else:\n",
    "                    sf_Net = ak.ones_like(temp_array['EventWeight'])\n",
    "                weights = weights*sf_Net\n",
    "\n",
    "                temp_hist = get_hist(temp_array[var],weights,nbins,xmin,xmax)\n",
    "\n",
    "                if sample.find('DY')!=-1:\n",
    "                    if (bkg_hists[reg][cat])[2]==None:\n",
    "                        (bkg_hists[reg][cat])[2] = temp_hist\n",
    "                    else:\n",
    "                        (bkg_hists[reg][cat])[2]+=temp_hist\n",
    "                if sample.find('TTJets')!=-1 or sample.find('WWTo2L2Nu')!=-1:\n",
    "                    if (bkg_hists[reg][cat])[1]==None:\n",
    "                        (bkg_hists[reg][cat])[1] = temp_hist\n",
    "                    else:\n",
    "                        (bkg_hists[reg][cat])[1]+=temp_hist\n",
    "                if sample.find('WZTo2Q2L')!=-1 or sample.find('ZZTo2Q2L')!=-1:\n",
    "                    if (bkg_hists[reg][cat])[0]==None:\n",
    "                        (bkg_hists[reg][cat])[0] = temp_hist\n",
    "                    else:\n",
    "                        (bkg_hists[reg][cat])[0]+=temp_hist\n",
    "            else:\n",
    "                temp_array = data_array_cut[reg][cat]\n",
    "                weights = np.ones_like(temp_array['EventWeight'])\n",
    "                print(f'data weight  = {weights}')\n",
    "                Data_hist[reg][cat] = get_hist(temp_array[var],weights,nbins,xmin,xmax)\n",
    "\n",
    "        #for sample in signal_lists:\n",
    "        #    temp_array = signal_array_cut[cat][sample]\n",
    "        #    weights = (temp_array['EventWeight']*lumi[2016]*samples_inf[sample][1]*10)/sumWeight[sample] #scale 10\n",
    "        #    sf_Net = GetParticleNetSignalSF(temp_array,tagger='ZvsQCD')\n",
    "        #    weights = weights*sf_Net\n",
    "        #    temp_hist = get_hist(temp_array[var],weights,nbins,xmin,xmax)\n",
    "        #    signal_hists[cat].append(temp_hist)\n",
    "\n",
    "    print(\"Fill done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce Alpha function\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
